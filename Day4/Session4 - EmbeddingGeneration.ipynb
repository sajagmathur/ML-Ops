{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9fe2db-b406-4b4c-a6f0-4e99f035266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers\n",
    "#install sentence transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d534b45-3e46-4fd2-9e7c-3ab8b8b7a28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector embedding:\n",
      "[-1.45817036e-02 -4.58822809e-02  1.10845007e-01 -4.39988337e-02\n",
      "  1.65814050e-02 -7.94640034e-02  4.22258377e-02 -1.65317282e-02\n",
      " -1.55437617e-02  4.83164415e-02 -1.68201737e-02  1.76585820e-02\n",
      " -4.52367887e-02 -5.01816459e-02 -4.18042652e-02  3.18047740e-02\n",
      "  3.95650491e-02  2.78501492e-03 -1.03391580e-01 -2.75364127e-02\n",
      " -1.32111460e-01 -6.80364370e-02 -4.02938873e-02  4.06657793e-02\n",
      "  1.48272794e-02  3.41950282e-02  2.75074784e-02  2.09841784e-02\n",
      "  5.03024226e-03 -9.64405835e-02  3.46349478e-02 -1.63914710e-02\n",
      "  4.30025458e-02  2.62444820e-02  1.83638707e-02  7.77741149e-02\n",
      "  7.65637681e-02 -3.90811972e-02 -1.15709864e-02  6.00426691e-03\n",
      "  2.84430273e-02 -7.52987862e-02  2.68959459e-02 -4.79204617e-02\n",
      "  2.03450155e-02  6.79492764e-03 -1.30942184e-02 -1.48797020e-01\n",
      "  2.09353510e-02  4.15965430e-02  1.44492285e-02 -1.19247362e-01\n",
      " -1.20014613e-02 -2.19731592e-02 -1.17056128e-02 -9.15818810e-02\n",
      "  2.55641174e-02  6.82068914e-02 -4.41451150e-04 -4.78844494e-02\n",
      " -5.46994209e-02  2.94140205e-02 -3.63360271e-02  5.67231514e-03\n",
      "  2.89692599e-02  1.01254918e-02  2.79493202e-02  1.63588002e-02\n",
      "  1.18726753e-02  3.70657779e-02 -5.25469743e-02  6.43271729e-02\n",
      " -1.71147939e-02  8.38129297e-02 -6.15799101e-03  1.30569980e-01\n",
      "  2.93464083e-02 -9.36862528e-02  4.38844338e-02 -1.51771428e-02\n",
      "  7.18400553e-02  2.36128047e-02 -2.80434135e-02 -1.14292307e-02\n",
      " -5.08980602e-02 -8.22375938e-02 -3.06596700e-02  6.48058876e-02\n",
      "  7.63675198e-02 -4.74705994e-02 -2.06314120e-02 -1.74310636e-02\n",
      " -6.90743029e-02  6.31132117e-03 -3.26276794e-02 -2.58408464e-03\n",
      "  2.37059454e-03 -1.51329609e-02 -9.01835784e-02  1.00845531e-01\n",
      " -7.01662078e-02  4.38585170e-02 -3.13470177e-02  7.36108795e-03\n",
      " -2.96850540e-02  1.97426639e-02 -3.32138017e-02  8.45294353e-03\n",
      "  5.43897375e-02 -1.11012675e-01  3.01482901e-02 -9.73297691e-04\n",
      "  2.44714916e-02 -3.49906576e-03 -3.52635607e-02 -5.43463640e-02\n",
      "  1.32195756e-03  1.27097433e-02 -6.37838338e-03  1.76131167e-02\n",
      "  1.97360311e-02  4.81994264e-02 -4.88862023e-03 -3.74480002e-02\n",
      " -4.17882539e-02 -6.91139325e-02  3.62865697e-03 -4.81766992e-33\n",
      "  2.54882523e-03 -2.19708867e-03  2.96402574e-02 -2.89000720e-02\n",
      "  8.32234845e-02 -3.20482627e-02 -7.26844417e-03 -5.90324663e-02\n",
      " -4.60820599e-03  1.75524633e-02 -4.57498170e-02  5.56768198e-03\n",
      " -8.63557160e-02 -1.78786945e-02  8.67370144e-02 -3.99236158e-02\n",
      "  6.03960231e-02  8.72662738e-02 -7.31823966e-02  1.30316494e-02\n",
      " -5.84350117e-02 -2.94863936e-02 -3.82035971e-02 -2.55757216e-02\n",
      "  3.96058187e-02  4.85271178e-02  1.06700072e-02 -2.59366930e-02\n",
      "  6.92388713e-02  6.86688572e-02  1.22334380e-02  8.96794870e-02\n",
      " -1.40385851e-02 -1.58329196e-02 -6.28571585e-02  3.85136157e-03\n",
      " -4.56783399e-02 -8.83193091e-02  3.37371312e-04 -3.22823832e-03\n",
      " -2.16291640e-02  3.93572077e-02  3.47107761e-02  6.84248060e-02\n",
      " -2.01842259e-03 -1.56712681e-02  3.34099052e-04 -8.68578479e-02\n",
      "  1.49337664e-01 -5.12084365e-02 -1.14470825e-03 -3.61381620e-02\n",
      "  3.29654627e-02  8.28715414e-03  4.83836010e-02 -1.34148654e-02\n",
      " -2.74479128e-02 -1.21148098e-02 -4.63328295e-04  5.27107716e-02\n",
      " -1.11847082e-02  3.46881934e-02  5.79662062e-02 -1.21140229e-02\n",
      "  2.57032663e-02 -1.39398957e-02  2.27407590e-02  1.10574879e-01\n",
      " -1.89550612e-02  5.22347800e-02 -5.50832152e-02  2.72993241e-02\n",
      "  3.75615358e-02 -6.26971349e-02 -3.96751165e-02 -5.97819611e-02\n",
      "  1.53767150e-02 -3.53085883e-02 -2.83000134e-02 -5.82851768e-02\n",
      "  7.66736269e-02 -5.35387956e-02 -7.34656528e-02 -8.10938850e-02\n",
      "  5.56154996e-02  3.87972146e-02 -5.03027551e-02 -4.22699191e-02\n",
      " -9.96896066e-03 -4.88018021e-02 -6.61024675e-02 -9.85399485e-02\n",
      "  3.64743099e-02 -5.56009933e-02 -1.18086278e-01  3.84781141e-33\n",
      "  1.48432124e-02 -9.24117118e-03 -6.94078654e-02  8.31139162e-02\n",
      " -5.71302846e-02  1.56685850e-03 -4.90642386e-03  2.75425743e-02\n",
      " -7.09809661e-02  1.42963231e-01 -1.18523370e-02 -4.89610694e-02\n",
      " -5.76360291e-03  1.28979208e-02  2.90794903e-03 -6.20444641e-02\n",
      "  6.12228625e-02 -4.44807895e-02  9.92542133e-02  7.66632659e-03\n",
      "  4.09681834e-02 -5.25226071e-03 -2.89526470e-02  4.57571745e-02\n",
      "  4.16388102e-02  3.27057652e-02 -1.34679362e-01  5.48788086e-02\n",
      " -1.96453445e-02  1.02958698e-02  2.94077154e-02  1.11158565e-02\n",
      "  2.32938491e-02 -1.11643434e-01  6.39972091e-02 -1.69978384e-02\n",
      "  4.49980050e-03  3.23169641e-02  7.28330836e-02 -2.77778916e-02\n",
      "  5.20069860e-02 -2.26696730e-02  2.49248445e-02  3.84094268e-02\n",
      " -2.38966551e-02  2.38926709e-02  2.81467978e-02 -1.86622739e-04\n",
      "  1.01222493e-01  5.00807129e-02 -1.22637056e-01 -2.13451143e-02\n",
      " -5.50962761e-02  1.38543909e-02 -2.31211670e-02  5.13032917e-03\n",
      " -7.17083961e-02  5.72815016e-02 -1.09714150e-01  1.84821375e-02\n",
      " -9.42736343e-02  1.31940423e-03  7.93904837e-05  5.35877720e-02\n",
      "  4.08588126e-02  6.37847558e-02  1.12263847e-03 -5.45753464e-02\n",
      " -9.44686756e-02 -4.08947319e-02  2.70904787e-02  1.21480776e-02\n",
      " -5.54670533e-03 -7.02168979e-03 -2.94335950e-02 -3.70322987e-02\n",
      "  2.77393702e-02 -3.22036818e-02 -3.26620750e-02  1.57906506e-02\n",
      "  4.05490398e-02 -2.92814169e-02  1.26192551e-02  1.29603222e-01\n",
      "  1.90429669e-02  1.81150623e-02 -4.13234998e-03  3.51064242e-02\n",
      " -5.09527847e-02 -2.69164983e-02  1.14121642e-02  5.99712543e-02\n",
      "  5.10186963e-02  6.94335401e-02  4.43731211e-02 -1.43832555e-08\n",
      " -2.61375383e-02  4.75934930e-02  5.95741160e-02 -1.71262119e-02\n",
      "  3.85352075e-02  1.00211974e-03 -5.34525998e-02 -6.52044686e-03\n",
      " -6.70047626e-02  5.31158671e-02  4.51302864e-02 -5.34113646e-02\n",
      " -4.75662313e-02  2.85489801e-02  1.39842078e-01  4.31001969e-02\n",
      "  6.85472637e-02 -2.60498468e-03 -5.29297218e-02  2.98168082e-02\n",
      " -3.78801525e-02  1.64084788e-02  8.39411095e-02 -4.06980067e-02\n",
      " -3.73396091e-02  5.49141802e-02  2.64818352e-02  1.68577582e-02\n",
      "  5.70571385e-02  4.97265495e-02  2.78336592e-02  2.50790138e-02\n",
      "  5.11893593e-02  8.03265497e-02 -3.43189500e-02  3.52407247e-02\n",
      " -5.27357403e-03  5.25383539e-02  4.79983315e-02 -6.59630746e-02\n",
      " -3.61274332e-02  2.04825569e-02  3.31833474e-02 -1.65637136e-02\n",
      " -3.62213440e-02  7.22791776e-02  1.31338723e-02 -5.83845563e-02\n",
      " -5.50954603e-02  6.70028031e-02  1.32496273e-02 -2.64385752e-02\n",
      "  5.99662401e-02  1.30855843e-01  1.31941885e-01  3.85193154e-02\n",
      "  2.26245597e-02 -1.04262792e-02  8.03495571e-02  1.00118099e-02\n",
      "  8.30825567e-02 -7.53271533e-03  6.52159229e-02 -2.24011838e-02]\n",
      "Shape: (384,)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model (e.g., all-MiniLM-L6-v2 is fast and effective)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Sentence to embed\n",
    "sentence = \"I Love MLOps\"\n",
    "\n",
    "# Generate the embedding\n",
    "embedding = model.encode(sentence)\n",
    "\n",
    "print(\"Vector embedding:\")\n",
    "print(embedding)\n",
    "print(\"Shape:\", embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fa208c-24d4-43d3-adb9-e7b3860a3f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "print(len(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ee0fbb7-20c4-4fbc-870f-356e12845e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (4.53.2)\n",
      "Requirement already satisfied: torch in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: huggingface_hub[hf_xet] in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (0.33.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.11.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (1.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub[hf_xet]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "!pip install huggingface_hub[hf_xet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e3cb12-662c-4be9-ac17-77ad4a75485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Explanation:\n",
      " Tell me what is 2+2.00+1.00+1.00?\"\n",
      "\n",
      "\"Not 2+2.00+1.00+1.00?\"\n",
      "\n",
      "\"Not 2+2.00+1.00+1.00?\n",
      "\n",
      "\"No, no, no, no, no, no 2+2.00+1.00+1.00?\"\n",
      "\n",
      "\"That is like asking if a bird had wings.\"\n",
      "\n",
      "\"That would be like asking if a bird had wings.\"\n",
      "\n",
      "\"That would be like asking if a bird had wings.\"\n",
      "\n",
      "\"I love birds. I love a bird. I love a bird.\"\n",
      "\n",
      "\"I love birds. I love a bird.\"\n",
      "\n",
      "\"I love a bird. I love a bird.\"\n",
      "\n",
      "\"Thank you, thank you. Thank you.\"\n",
      "\n",
      "\"Thank you, thank you.\"\n",
      "\n",
      "\"Thank you, thank you. Thank you!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "lm_name = \"gpt2\"  # Small language model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(lm_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(lm_name)\n",
    "\n",
    "prompt = \"Tell me what is 2+2.\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs['input_ids'],\n",
    "    max_length=200,               # 10,000 is very long; 200 is typical for explanation\n",
    "    do_sample=True,\n",
    "    temperature=0.8,\n",
    "    pad_token_id=tokenizer.eos_token_id  # Avoid warning by explicitly setting pad_token_id\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"\\nGenerated Explanation:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0cc3ca0-f318-45f2-8da5-3508ceee2027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (2.165.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (4.25.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (4.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.73.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sajag177350\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 8.5 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.73.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 2.1/4.3 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.3 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 10.0 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Installing collected packages: protobuf, grpcio, grpcio-status, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-generativeai-0.8.5 grpcio-1.73.1 grpcio-status-1.71.2 protobuf-5.29.5\n"
     ]
    }
   ],
   "source": [
    "#using gemini\n",
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a97d3f51-6466-4914-90d8-ad70d37291e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama is the 44th President of the United States, serving two terms from 2009 to 2017.  The first African American president, he was a community organizer, civil rights attorney, and senator from Illinois before his election.  His presidency saw the passage of the Affordable Care Act, the end of the Iraq War, and the killing of Osama bin Laden.  He's known for his eloquence, charisma, and focus on expanding healthcare access and addressing climate change.  Post-presidency, he remains a prominent figure through his foundation and public speaking.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"<enter api key here>\")\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash-latest\")\n",
    "response = model.generate_content(\"Who is barak obama? Tell in 100 words.\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beb22b3e-c2cd-489b-9310-082b15880b6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/veo-2.0-generate-001\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog\n",
      "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    print(m.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdbf03f-f41b-4862-8afe-e392930749aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
